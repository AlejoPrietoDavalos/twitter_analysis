{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aprieto/.personal/scraping_kit/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-01-13 13:27:18.180509: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-13 13:27:18.216193: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-13 13:27:18.216228: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-13 13:27:18.217493: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-13 13:27:18.224481: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-13 13:27:18.225084: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-13 13:27:19.382212: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection Names: ['trends', 'raw', 'search']\n",
      "Bots: bots=[BotScraper(acc_name='Vera')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from twitter_trends import ArgsTwitterTrends, ParamsTwitterTrends, WOEIDCountry, requests_and_process\n",
    "from scraping_kit import BotScraper, load_db_and_bots\n",
    "from scraping_kit.db.models.search import Search\n",
    "\n",
    "\n",
    "path_data = Path(\"data\")\n",
    "db_tw, bots = load_db_and_bots(path_data, \"scrape_tw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraping_kit.db.models.topics import Topic\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "max_workers = 2\n",
    "n_first_texts = 10\n",
    "\n",
    "topics = []\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as pool:\n",
    "    iter_futures = (pool.submit(Topic.create_from_search, Search(**search_doc), classifier, topics_1, n_first_texts)\n",
    "                    for search_doc in searchs_docs)#db_tw.coll.search.find())\n",
    "\n",
    "    for i, future in enumerate(as_completed(iter_futures)):\n",
    "        topic = future.result()\n",
    "        topics.append(topic)\n",
    "\n",
    "#search = Search(**db_tw.coll.search.find_one())\n",
    "#topic = Topic.create_from_search(search, classifier, topics_1, n_first_texts=10)\n",
    "#topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, search_doc in enumerate(db_tw.coll.search.find()):\n",
    "    search = Search(**search_doc)\n",
    "    #texts = search.get_texts()\n",
    "    #len_texts.append(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraping_kit.db.models.topics import Topic\n",
    "\n",
    "topics: list[Topic] = []\n",
    "for doc in db_tw.coll.topics.find():\n",
    "    topic = Topic(**doc)\n",
    "    topics.append(topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"CLASSES_TWITTER.json\", \"r\") as f:\n",
    "    CLASSES_TWITTER = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "text = topics[0].topics_1.text\n",
    "labels, scores = topics[0].get_labels_scores_thresh(threshold)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(labels))\n",
    "TOPICS2 = []\n",
    "for label in labels:\n",
    "    TOPICS2.extend(CLASSES_TWITTER[label])\n",
    "TOPICS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = classifier(\n",
    "    text,\n",
    "    candidate_labels = TOPICS2,\n",
    "    multi_label = True\n",
    ")\n",
    "asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"asd.json\", \"w\") as f:\n",
    "    json.dump(topics, f, default=lambda obj: obj.isoformat())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
