{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from scraping_kit import load_db_and_bots\n",
    "from scraping_kit.db.leak import get_trend_names_uniques\n",
    "\n",
    "path_data = Path(\"data\")\n",
    "db_tw, bots = load_db_and_bots(path_data, \"scrape_tw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from requests import Response\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "from twitter45.params import ArgsSearch, ParamsSearch\n",
    "from scraping_kit.db.models import Trends, Topic, Search, User\n",
    "from scraping_kit import DBTwitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for doc in db_tw.coll.trends.find():\n",
    "#    for trend in doc[\"trends\"]:\n",
    "#        req_args = ArgsSearch(params=ParamsSearch(query=trend[\"query\"]))\n",
    "#        trend[\"topic\"] = None #get_topic(req_args)\n",
    "#    db_tw.coll.trends.update_one({\"_id\": doc[\"_id\"]}, {\"$set\": {\"trends\": doc[\"trends\"]}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: Borrar, esto hacÃ­a el resumen del texto.\n",
    "# def summary_text(summarizer, text: str, max_length=30) -> str:\n",
    "#     input_length = len(text.split())\n",
    "#     if input_length < max_length:\n",
    "#         return text\n",
    "#     adjusted_max_length = max(30, input_length // 2)\n",
    "#     return summarizer(text, max_length=adjusted_max_length)[0][\"summary_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraping_kit.db.models.topics import Topic, get_topic_classes\n",
    "from scraping_kit.dl import instance_classifier\n",
    "MAX_WORKERS = 10\n",
    "N_TEXT_CONTEXT = 10\n",
    "\n",
    "#trend_names_uniques = get_trend_names_uniques(db_tw, not_in_topics=True, not_in_searchs=True, reverse=False)\n",
    "#failed_requests = db_tw.coll.collect_searchs_by_trends(\n",
    "#    trend_names_uniques,\n",
    "#    bots,\n",
    "#    MAX_WORKERS\n",
    "#)\n",
    "#failed_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "path_topic_classes = path_data / \"CLASSES_TWITTER.json\"\n",
    "topics_1_to_topics_2, topics_1 = get_topic_classes(path_topic_classes)\n",
    "\n",
    "\n",
    "\n",
    "db_tw.create_topics_trends(db_tw, topics_1, n_text_context=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_tw.get_trends_df_accumulated(\n",
    "    date_from = datetime(2023, 12, 1),\n",
    "    date_to = datetime(2024, 1, 13)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
